# Projet d'analyse de logs HTTP en temps rÃ©el â€“ Chaussettes.io

Ce projet propose un systÃ¨me dâ€™analyse **en temps rÃ©el** des logs HTTP pour **Chaussettes.io**, entreprise spÃ©cialisÃ©e dans la vente de chaussettes personnalisÃ©es.

Il sâ€™appuie sur :
- **Kafka** pour la transmission des Ã©vÃ©nements
- **Spark Structured Streaming** pour leur traitement
- Une gÃ©nÃ©ration de logs simulÃ©s configurable

## ğŸ§­ Objectifs

- ğŸ”„ Lire les logs depuis Kafka (`http-logs`)
- ğŸš¨ DÃ©clencher des alertes sur comportement anormal (ex. >5 erreurs HTTP en <5 sec)
- ğŸ“Š GÃ©nÃ©rer des mÃ©triques utiles (frÃ©quence dâ€™erreurs par IP/URL)
- ğŸ” IntÃ©grer les bases de la sÃ©curitÃ© dans lâ€™architecture
- ğŸ” Automatiser lâ€™infrastructure (Docker, scripts)

## ğŸ“ Structure du projet

```text
project-root/
â”œâ”€â”€ .env                        # variables dâ€™environnement (ex. chemins, credentials)
â”œâ”€â”€ .gitignore                  # rÃ¨gles dâ€™exclusion Git
â”œâ”€â”€ bin/                        # utilitaires Hadoop (winutils, etc.)
â”œâ”€â”€ certs/                      # certificats CA + keystore/truststore
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ kafka_config.json       # configuration Kafka (gÃ©nÃ©rÃ©e depuis template)
â”‚   â””â”€â”€ log4j.properties        # configuration Log4j pour Spark
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ generator.log           # historique complet des logs simulÃ©s
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ alerts/                 # alertes dÃ©tectÃ©es (alerts.txt)
â”‚   â””â”€â”€ checkpoints/            # RÃ©pertoire des points de reprise de Spark Structured Streaming
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ log_generator_kafka.py  # script de gÃ©nÃ©ration et envoi de logs
â”‚   â””â”€â”€ log_analyzer_kafka.py   # application Spark Structured Streaming
â”œâ”€â”€ docker-compose.yml          # services Zookeeper + Kafka sÃ©curisÃ©s
â”œâ”€â”€ requirements.txt            # dÃ©pendances Python
â””â”€â”€ README.md                   # documentation du projet
```

## âœ… PrÃ©requis

### Configurer lâ€™environnement

```powershell
$env:HADOOP_HOME = "$(Get-Location)"
$env:PATH = "$($env:HADOOP_HOME)\bin;$env:PATH"
$env:PYSPARK_PYTHON="C:\path\to\python.exe"
$env:PYSPARK_DRIVER_PYTHON="C:\path\to\python.exe"
```
### Creer les Variables dâ€™environnement

CrÃ©ez un fichier `.env` Ã  la racine (non versionnÃ©) :

```
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin-secret
CLIENT_USERNAME=client
CLIENT_PASSWORD=client-secret
JKS_PASSWORD=password1234
```
---

### Ajouter les Certificats et sÃ©curitÃ©

```powershell
Get-Content .env |
  ForEach-Object {
    if ($_ -and $_ -notmatch '^\s*#') {
      $kv = $_ -split '=', 2
      Set-Item -Path "Env:\$($kv[0])" -Value $kv[1]
    }
  }
openssl genrsa -out certs/ca-key.pem 2048
openssl req -x509 -new -nodes -key certs/ca-key.pem -sha256 -days 365 -out certs/ca-cert.pem -subj "//CN=Chaussettes.io Root CA"
keytool -genkeypair -alias kafka-broker -keyalg RSA -keystore certs/kafka.server.keystore.jks -storepass $Env:JKS_PASSWORD -keypass $Env:JKS_PASSWORD -validity 365 -dname "CN=localhost,OU=IT,O=Chaussettes.io,L=Paris,ST=IDF,C=FR"
keytool -certreq -alias kafka-broker -keystore certs/kafka.server.keystore.jks -file certs/kafka-broker.csr -storepass $Env:JKS_PASSWORD
openssl x509 -req -in certs/kafka-broker.csr -CA certs/ca-cert.pem -CAkey certs/ca-key.pem -CAcreateserial -out certs/kafka-broker-signed.pem -days 365 -sha256
keytool -importcert -alias CARoot -file certs/ca-cert.pem -keystore certs/kafka.server.keystore.jks -storepass $Env:JKS_PASSWORD -noprompt
keytool -importcert -alias kafka-broker -file certs/kafka-broker-signed.pem -keystore certs/kafka.server.keystore.jks -storepass $Env:JKS_PASSWORD
keytool -importcert -alias CARoot -file certs/ca-cert.pem -keystore certs/kafka.client.truststore.jks -storepass $Env:JKS_PASSWORD -noprompt
```

## ğŸš€ ExÃ©cution

### 1. DÃ©marrer Kafka et Zookeeper

```powershell
docker-compose -f docker-compose.yml up -d --build
```

### 2. Lancer le gÃ©nÃ©rateur de logs

```powershell
python src/log_generator_kafka.py --mode kafka --rate 3 --error-rate 0.5
```

### 3. DÃ©marrer lâ€™analyseur Spark

```powershell
spark-submit `
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 `
  --conf "spark.driver.extraJavaOptions=-Dlog4j.configuration=file:config/log4j.properties" `
  src/log_analyzer_kafka.py
```

Et voilÃ  une interface web Spark UI est disponible sur http://localhost:4040/ pour suivre en temps rÃ©el vos jobs et voir les mÃ©triques dâ€™exÃ©cution !

## ğŸ“ˆ FonctionnalitÃ©s implÃ©mentÃ©es

- GÃ©nÃ©ration de logs HTTP personnalisable via arguments
- Transmission sÃ©curisÃ©e (SASL_SSL) vers Kafka
- Analyse en streaming avec Spark (dÃ©tection dâ€™erreurs)
- Alertes persistantes et console